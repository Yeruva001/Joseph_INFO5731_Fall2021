{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ha3MGlx1ZKC6"
   },
   "source": [
    "## The second In-class-exercise (09/22/2022, 40 points in total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOCBFJE9ZKC8"
   },
   "source": [
    "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xT9qQ5BZKC8"
   },
   "source": [
    "Question 1 (10 points): Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DdN2uKLTZKC8",
    "outputId": "2124c409-d6ea-41a7-8385-955735294db5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPlease write you answer here:\\n\\nThe research question that I have as a primary concern the are impacts and results of an Earth-wide temperature boost and How to free the world?\\n\\nThis is my examination question. The information ought to be satelite pictures of regions where we can identify we can identify global warming and chances of global warming in near future.\\n\\n\\nAn enormous dataset is required for the question. The data needs to cover the whole areas yet we can be intended for specific region or nation so we might require less information.\\n\\nThe dataset should be satelite pictures that we can find it from many free open-source sites like kaggle. We might get an enormous amount of raw substance.\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
    "\n",
    "'''\n",
    "Please write you answer here:\n",
    "\n",
    "The research question that I have as a primary concern the are impacts and results of an Earth-wide temperature boost and How to free the world?\n",
    "\n",
    "This is my examination question. The information ought to be satelite pictures of regions where we can identify we can identify global warming and chances of global warming in near future.\n",
    "\n",
    "\n",
    "An enormous dataset is required for the question. The data needs to cover the whole areas yet we can be intended for specific region or nation so we might require less information.\n",
    "\n",
    "The dataset should be satelite pictures that we can find it from many free open-source sites like kaggle. We might get an enormous amount of raw substance.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hh8u9_KZKC9"
   },
   "source": [
    "Question 2 (10 points): Write python code to collect 1000 data samples you discussed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cANcqpb9ZKC9",
    "outputId": "99260636-c6d5-4089-9606-0c62de2da6ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.amazon.com/s?k=iphone+10\n",
      "https://www.amazon.com/s?k=UnderArmour+shoes+men\n"
     ]
    }
   ],
   "source": [
    "# You code here (Please add comments in the code):\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def getAmazon(sea_qu):\n",
    "    url1=\"https://www.amazon.com/s?k=\"+sea_qu\n",
    "    print(url1)\n",
    "    pg=requests.get(url1,headers=header)\n",
    "    if pg.status_code==200:\n",
    "        return pg\n",
    "    else:\n",
    "        return \"Error\"\n",
    "\n",
    "sea_qu=\"iphone+10\"\n",
    "b_url=\"https://www.amazon.com/s?k=\"\n",
    "\n",
    "url1=b_url+sea_qu\n",
    "\n",
    "header={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36','referer':'https://www.amazon.com/s?k=nike+shoes+men&crid=28WRS5SFLWWZ6&sprefix=nike%2Caps%2C357&ref=nb_sb_ss_organic-diversity_2_4'}\n",
    "\n",
    "sear_resp=requests.get(url1,headers=header)\n",
    "\n",
    "cook={} \n",
    "cook = sear_resp.cookies\n",
    "prodt_name=[]\n",
    "resp=getAmazon('iphone+10')\n",
    "so=BeautifulSoup(resp.content)\n",
    "for i in so.findAll(\"span\",{'class':'a-size-base-plus a-color-base a-text-normal'}): \n",
    "    prodt_name.append(i.text) \n",
    "def Searchasing(asin1):\n",
    "    url1=\"https://www.amazon.com/dp/\"+asin1\n",
    "    print(url1)\n",
    "    pg=requests.get(url1,cookies=cook,headers=header)\n",
    "    if pg.status_code==200:\n",
    "        return pg\n",
    "    else:\n",
    "        return \"Error\"\n",
    "def Searchrev(rev_li):\n",
    "    url=\"https://www.amazon.com\"+rev_li\n",
    "    print(url)\n",
    "    pg=requests.get(url,cookies=cook,headers=header)\n",
    "    if pg.status_code==200:\n",
    "        return pg\n",
    "    else:\n",
    "        return \"Error\"\n",
    "data_asign=[]\n",
    "resp=getAmazon('UnderArmour+shoes+men')\n",
    "so=BeautifulSoup(resp.content)\n",
    "\n",
    "for i in so.findAll(\"div\",class_=\"sg-col-4-of-12 s-result-item s-asin sg-col-4-of-16 AdHolder sg-col sg-col-4-of-20\"):\n",
    "\n",
    "    data_asign.append(i['data-asign'])\n",
    "li=[]\n",
    "for i in range(len(data_asign)):\n",
    "    resp=Searchasing(data_asign[i])\n",
    "    so=BeautifulSoup(resp.content)\n",
    "    for i in so.findAll(\"a\",{'data-hook':\"see-all-reviews-link-foot\"}):\n",
    "        li.append(i['href'])\n",
    "rev=[]\n",
    "rev_title = []\n",
    "rev_date = []\n",
    "rev_star = []\n",
    "name1 = []\n",
    "for j in range(len(li)):\n",
    "    for k in range(50):\n",
    "        resp=Searchrev(li[j]+'&pageNumber='+str(k))\n",
    "        so=BeautifulSoup(res.content)\n",
    "        for i in so.findAll(\"span\",{'data-hook':\"review-body\"}):\n",
    "            rev.append(i.text)\n",
    "        for i in so.findAll(\"span\",{'data-hook':\"review-title\"}):\n",
    "            rev_title.append(i.text)\n",
    "        for i in so.findAll(\"span\",{'data-hook':\"review-date\"}):\n",
    "            rev_date.append(i.text)\n",
    "        for i in so.findAll(\"span\",{'data-hook':\"review-star-rating\"}):\n",
    "            rev_star.append(i.text)\n",
    "        for i in so.findAll('span',class_='a-profile-name'):\n",
    "            name1.append(i.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xh8K49j4ZKC-"
   },
   "source": [
    "Question 3 (10 points): Write python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"information retrieval\". The articles should be published in the last 10 years (2012-2022).\n",
    "\n",
    "The following information of the article needs to be collected:\n",
    "\n",
    "(1) Title\n",
    "\n",
    "(2) Venue/journal/conference being published\n",
    "\n",
    "(3) Year\n",
    "\n",
    "(4) Authors\n",
    "\n",
    "(5) Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iEQMHGotZKC_",
    "outputId": "46c2ae09-eaf0-423b-c046-bd6f03d79b2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "[BOOK][B] Programming python\n",
      " \n",
      " \n",
      "[PDF] htw-berlin.de\n",
      " \n",
      " \n",
      "M Lutz \n",
      " \n",
      " \n",
      "[2001]\n",
      "‚Ä¶ of an African rock python and the topic of Python programming is a trademark of O'Reilly & ‚Ä¶ \n",
      "edition presents Python programming by advanced examples. Becoming proficient in Python ‚Ä¶\n",
      "[BOOK][B] Core python programming\n",
      " \n",
      " \n",
      "[PDF] 14.99.188.242\n",
      " \n",
      " \n",
      "W Chun \n",
      " \n",
      " \n",
      "[2001]\n",
      "‚Ä¶ Python is a fully object-oriented programming language and was designed that way from the \n",
      "beginning. However, Python ‚Ä¶ can transition to ‚ÄúOO‚Äù programming anytime you are ready to ‚Ä¶\n",
      "[BOOK][B] Python programming: an introduction to computer science\n",
      " \n",
      " \n",
      "[PDF] slu.edu\n",
      " \n",
      " \n",
      "JM Zelle \n",
      " \n",
      " \n",
      "[2004]\n",
      "‚Ä¶ Although I use Python as the language, teaching Python is not the main point of this book. \n",
      "Rather, Python is used to illustrate fundamental principles of design and programming that ‚Ä¶\n",
      "[BOOK][B] A primer on scientific programming with Python\n",
      " \n",
      " \n",
      "[PDF] ukh.ac.id\n",
      " \n",
      " \n",
      "HP Langtangen, HP Langtangen \n",
      " \n",
      " \n",
      "[2011]\n",
      "‚Ä¶ computer programming using examples from mathematics and the natural sciences. We have \n",
      "chosen to use the Python programming ‚Ä¶ Python is easy to learn and very well suited for an ‚Ä¶\n",
      "[PDF][PDF] Python: a programming language for software integration and development\n",
      " \n",
      " \n",
      "[PDF] academia.edu\n",
      " \n",
      " \n",
      "MF Sanner¬†\n",
      " \n",
      " \n",
      "[1999]\n",
      "‚Ä¶ An example I like to give to illustrate these points is our first PDB parser for Python we \n",
      "which developed as a C extension because we though that Python code would not be efficient ‚Ä¶\n",
      "[BOOK][B] Programming python: powerful object-oriented programming\n",
      " \n",
      " \n",
      "Programming python: powerful object-oriented programming\n",
      " \n",
      " \n",
      "M Lutz \n",
      " \n",
      " \n",
      "[2010]\n",
      "‚Ä¶ This book explores ways to apply the Python programming language in common application \n",
      "domains and realistically scaled tasks. It‚Äôs about what you can do with the language once ‚Ä¶\n",
      "[PDF][PDF] Interactively testing remote servers using the Python programming language\n",
      " \n",
      " \n",
      "[PDF] cwi.nl\n",
      " \n",
      " \n",
      "G van Rossum, J de Boer¬†\n",
      " \n",
      " \n",
      "[1991]\n",
      "This paper describes hovv two tools that were developed quite independently gained in \n",
      "power by a well-designed connection between them. The tools are Python, an interpreted ‚Ä¶\n",
      "[BOOK][B] Python and Tkinter programming\n",
      " \n",
      " \n",
      "[PDF] academia.edu\n",
      " \n",
      " \n",
      "JE Grayson \n",
      " \n",
      " \n",
      "[2000]\n",
      "‚Ä¶ features of Python‚Äôs support for object-oriented programming so that those of you familiar \n",
      "with C++ or Java can understand how your experience may be applied to Python. Chapter 2 ‚Ä¶\n",
      "Machine Learning Made Easy: A Review of Scikit-learn Package in Python Programming Language\n",
      " \n",
      " \n",
      "Machine Learning Made Easy: A Review of Scikit-learn Package in Python Programming Language\n",
      " \n",
      " \n",
      "J Hao, TK Ho¬†\n",
      " \n",
      " \n",
      "[2019]\n",
      "‚Ä¶ been developed and implemented in a variety of programming languages over the past 20 \n",
      "years. ‚Ä¶ Then, we review Scikit-learn, a machine learning package in the Python programming ‚Ä¶\n",
      "[BOOK][B] Learning python: Powerful object-oriented programming\n",
      " \n",
      " \n",
      "[PDF] 117.3.71.125\n",
      " \n",
      " \n",
      "M Lutz \n",
      " \n",
      " \n",
      "[2013]\n",
      "‚Ä¶ in Python training, the author of Python's earliest and bestselling texts, and a pioneering figure \n",
      "in the Python ‚Ä¶ Programming Python, 4th Edition and Python Pocket Reference, 4th Edition. ‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "# You code here (Please add comments in the code):\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import urllib.request\n",
    "import re\n",
    "  \n",
    "Fi = open(\"out1.csv\", \"a\")\n",
    "HD = ({'User-Agent':\n",
    "           'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36',\n",
    "                           'Accept-Language': 'en-US, en;q=0.5'})\n",
    "\n",
    "wp = requests.get('https://scholar.google.com/scholar?start=0&q=python+programming&hl=en&as_sdt=0,44', headers=HD)\n",
    "Sp = bs(wp.content,'html.parser')\n",
    "print(wp)\n",
    "for i in Sp.select('[data-lid]'):\n",
    "  print(i.select('h3')[0].get_text())\n",
    "  print(\" \")\n",
    "  print(\" \")\n",
    "  print(i.select('a')[0].get_text())\n",
    "  print(\" \")\n",
    "  print(\" \")\n",
    "  print(i.find_all('div',class_='gs_a')[0].get_text().split('-')[0])\n",
    "  print(\" \")\n",
    "  print(\" \")\n",
    "  a1=i.find_all('div',class_='gs_a')[0].get_text()\n",
    "  t1 = re.findall(r'\\d+', a1)\n",
    "  r1 = list(map(int, t1))\n",
    "  print(r1)\n",
    " \n",
    "  print(i.find_all('div',class_='gs_rs')[0].get_text())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUzB2f2DZKC_"
   },
   "source": [
    "Question 4 (10 points): Write python code to collect 1000 posts from Twitter, or Facebook, or Instagram. You can either use hashtags, keywords, user_name, user_id, or other information to collect the data. \n",
    "\n",
    "The following information needs to be collected:\n",
    "\n",
    "(1) User_name\n",
    "\n",
    "(2) Posted time\n",
    "\n",
    "(3) Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "H0LGy7yuZKDA",
    "outputId": "c61c3cf2-547d-4214-9788-23ef2fe72e3e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7b048a37-829c-47ea-b1c0-305b9147a381\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MULTILINGUAL NEWS SERVICE HINDI 25 September 2...</td>\n",
       "      <td>2022-09-26 04:03:59</td>\n",
       "      <td>1574248390396739585</td>\n",
       "      <td>NEMBC</td>\n",
       "      <td>nembc_official</td>\n",
       "      <td>351431656</td>\n",
       "      <td>Melbourne, Australia</td>\n",
       "      <td>https://t.co/iQI5VbZu58</td>\n",
       "      <td>The National Ethnic &amp; Multicultural Broadcaste...</td>\n",
       "      <td>False</td>\n",
       "      <td>1293</td>\n",
       "      <td>1475</td>\n",
       "      <td>905</td>\n",
       "      <td>8662</td>\n",
       "      <td>37</td>\n",
       "      <td>2011-08-09 07:16:23</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/113182925...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @PTI_News: Single day rise of 4,129¬†new cor...</td>\n",
       "      <td>2022-09-26 04:03:45</td>\n",
       "      <td>1574248332955774976</td>\n",
       "      <td>CA Aditya Kansili</td>\n",
       "      <td>AdityaKansili</td>\n",
       "      <td>1199615373101785088</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>Big Fan Of-| Numbers| Virat Kohli| Akshay Kuma...</td>\n",
       "      <td>False</td>\n",
       "      <td>557</td>\n",
       "      <td>586</td>\n",
       "      <td>19889</td>\n",
       "      <td>12908</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-27 09:06:32</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/156963816...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @PTI_News: Single day rise of 4,129¬†new cor...</td>\n",
       "      <td>2022-09-26 04:03:44</td>\n",
       "      <td>1574248330234044418</td>\n",
       "      <td>Mohammed Waseem</td>\n",
       "      <td>erummohammed58</td>\n",
       "      <td>1564531054987575296</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>None</td>\n",
       "      <td>Loves traveling and literally hate communal bi...</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>121</td>\n",
       "      <td>8751</td>\n",
       "      <td>6953</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-08-30 08:31:11</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/156741439...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @NatGeo: Experts say three types of headach...</td>\n",
       "      <td>2022-09-26 04:03:36</td>\n",
       "      <td>1574248296268197888</td>\n",
       "      <td>Paul Mick üá∫üá¶üá∫üá≥üá∫üá≤</td>\n",
       "      <td>PaulMick</td>\n",
       "      <td>26514883</td>\n",
       "      <td>Delaware County PA</td>\n",
       "      <td>None</td>\n",
       "      <td>Mick Music ~ PhillyEDGE ~ ICON Magazine ~ Rock...</td>\n",
       "      <td>False</td>\n",
       "      <td>2665</td>\n",
       "      <td>5004</td>\n",
       "      <td>359228</td>\n",
       "      <td>530686</td>\n",
       "      <td>492</td>\n",
       "      <td>2009-03-25 15:05:42</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/139801259...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @EricKleefeld: @AriDrennen @mount_bees Some...</td>\n",
       "      <td>2022-09-26 04:03:18</td>\n",
       "      <td>1574248220066283521</td>\n",
       "      <td>poweredbycoffee</td>\n",
       "      <td>poweredbycoffe2</td>\n",
       "      <td>1326231133751828481</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>Just here to observe and occasionally amplify ...</td>\n",
       "      <td>False</td>\n",
       "      <td>68</td>\n",
       "      <td>51</td>\n",
       "      <td>24515</td>\n",
       "      <td>2571</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-11-10 18:32:04</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/140282858...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>RT @jsolomonReports: Feds award $1 million to ...</td>\n",
       "      <td>2022-09-25 23:46:29</td>\n",
       "      <td>1574183589524099072</td>\n",
       "      <td>Roger Harmon</td>\n",
       "      <td>RogerHa16981722</td>\n",
       "      <td>1424478399037313024</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>Truth Social</td>\n",
       "      <td>False</td>\n",
       "      <td>297</td>\n",
       "      <td>348</td>\n",
       "      <td>7599</td>\n",
       "      <td>16735</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-08-08 21:11:55</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/148562684...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Japan expands simplified coronavirus infection...</td>\n",
       "      <td>2022-09-25 23:46:26</td>\n",
       "      <td>1574183579265167360</td>\n",
       "      <td>Andreas_sensei-Slava Ukrayini!</td>\n",
       "      <td>Bunny_Godfather</td>\n",
       "      <td>36287570</td>\n",
       "      <td>Yokohama</td>\n",
       "      <td>None</td>\n",
       "      <td>German by birth but living in Japan since 1995...</td>\n",
       "      <td>False</td>\n",
       "      <td>1708</td>\n",
       "      <td>1905</td>\n",
       "      <td>13995</td>\n",
       "      <td>37365</td>\n",
       "      <td>49</td>\n",
       "      <td>2009-04-29 04:32:44</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/149749854...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Stops at '21, but suffice it to say, Cuba, Sou...</td>\n",
       "      <td>2022-09-25 23:45:48</td>\n",
       "      <td>1574183419545804800</td>\n",
       "      <td>Smemm</td>\n",
       "      <td>Smemu4</td>\n",
       "      <td>1321842651939794949</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>78</td>\n",
       "      <td>110</td>\n",
       "      <td>7568</td>\n",
       "      <td>20382</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-10-29 15:54:00</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/132548918...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The CHP Inbound Travel Website has been update...</td>\n",
       "      <td>2022-09-25 23:45:39</td>\n",
       "      <td>1574183382065750016</td>\n",
       "      <td>Aaron Busch</td>\n",
       "      <td>tripperhead</td>\n",
       "      <td>27402457</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>None</td>\n",
       "      <td>üá≠üá∞ COVID-19 updates and news. \\n\\n‚òï: https://t...</td>\n",
       "      <td>False</td>\n",
       "      <td>33094</td>\n",
       "      <td>104</td>\n",
       "      <td>41509</td>\n",
       "      <td>62310</td>\n",
       "      <td>198</td>\n",
       "      <td>2009-03-29 09:10:01</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/821173867...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>üëçüëçüëçüëçüëçüëçüëç\\nRepublican Rep. Claudia Tenney Demand...</td>\n",
       "      <td>2022-09-25 23:45:37</td>\n",
       "      <td>1574183372179623942</td>\n",
       "      <td>Ultra Maga Dawn</td>\n",
       "      <td>dulcinea5002</td>\n",
       "      <td>1454418012</td>\n",
       "      <td>Great State of Texas</td>\n",
       "      <td>None</td>\n",
       "      <td>Retired Federal employee of 38 years.  Husband...</td>\n",
       "      <td>False</td>\n",
       "      <td>4018</td>\n",
       "      <td>4183</td>\n",
       "      <td>93762</td>\n",
       "      <td>38601</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-05-24 14:54:41</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/117486271...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 19 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b048a37-829c-47ea-b1c0-305b9147a381')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-7b048a37-829c-47ea-b1c0-305b9147a381 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-7b048a37-829c-47ea-b1c0-305b9147a381');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                    0                   1   \\\n",
       "0    MULTILINGUAL NEWS SERVICE HINDI 25 September 2... 2022-09-26 04:03:59   \n",
       "1    RT @PTI_News: Single day rise of 4,129¬†new cor... 2022-09-26 04:03:45   \n",
       "2    RT @PTI_News: Single day rise of 4,129¬†new cor... 2022-09-26 04:03:44   \n",
       "3    RT @NatGeo: Experts say three types of headach... 2022-09-26 04:03:36   \n",
       "4    RT @EricKleefeld: @AriDrennen @mount_bees Some... 2022-09-26 04:03:18   \n",
       "..                                                 ...                 ...   \n",
       "995  RT @jsolomonReports: Feds award $1 million to ... 2022-09-25 23:46:29   \n",
       "996  Japan expands simplified coronavirus infection... 2022-09-25 23:46:26   \n",
       "997  Stops at '21, but suffice it to say, Cuba, Sou... 2022-09-25 23:45:48   \n",
       "998  The CHP Inbound Travel Website has been update... 2022-09-25 23:45:39   \n",
       "999  üëçüëçüëçüëçüëçüëçüëç\\nRepublican Rep. Claudia Tenney Demand... 2022-09-25 23:45:37   \n",
       "\n",
       "                      2                               3                4   \\\n",
       "0    1574248390396739585                           NEMBC   nembc_official   \n",
       "1    1574248332955774976               CA Aditya Kansili    AdityaKansili   \n",
       "2    1574248330234044418                 Mohammed Waseem   erummohammed58   \n",
       "3    1574248296268197888                Paul Mick üá∫üá¶üá∫üá≥üá∫üá≤         PaulMick   \n",
       "4    1574248220066283521                 poweredbycoffee  poweredbycoffe2   \n",
       "..                   ...                             ...              ...   \n",
       "995  1574183589524099072                    Roger Harmon  RogerHa16981722   \n",
       "996  1574183579265167360  Andreas_sensei-Slava Ukrayini!  Bunny_Godfather   \n",
       "997  1574183419545804800                           Smemm           Smemu4   \n",
       "998  1574183382065750016                     Aaron Busch      tripperhead   \n",
       "999  1574183372179623942                 Ultra Maga Dawn     dulcinea5002   \n",
       "\n",
       "                      5                     6                        7   \\\n",
       "0              351431656  Melbourne, Australia  https://t.co/iQI5VbZu58   \n",
       "1    1199615373101785088                                           None   \n",
       "2    1564531054987575296            Bangalore                      None   \n",
       "3               26514883    Delaware County PA                     None   \n",
       "4    1326231133751828481                                           None   \n",
       "..                   ...                   ...                      ...   \n",
       "995  1424478399037313024                                           None   \n",
       "996             36287570              Yokohama                     None   \n",
       "997  1321842651939794949                                           None   \n",
       "998             27402457             Hong Kong                     None   \n",
       "999           1454418012  Great State of Texas                     None   \n",
       "\n",
       "                                                    8      9      10    11  \\\n",
       "0    The National Ethnic & Multicultural Broadcaste...  False   1293  1475   \n",
       "1    Big Fan Of-| Numbers| Virat Kohli| Akshay Kuma...  False    557   586   \n",
       "2    Loves traveling and literally hate communal bi...  False     32   121   \n",
       "3    Mick Music ~ PhillyEDGE ~ ICON Magazine ~ Rock...  False   2665  5004   \n",
       "4    Just here to observe and occasionally amplify ...  False     68    51   \n",
       "..                                                 ...    ...    ...   ...   \n",
       "995                                       Truth Social  False    297   348   \n",
       "996  German by birth but living in Japan since 1995...  False   1708  1905   \n",
       "997                                                     False     78   110   \n",
       "998  üá≠üá∞ COVID-19 updates and news. \\n\\n‚òï: https://t...  False  33094   104   \n",
       "999  Retired Federal employee of 38 years.  Husband...  False   4018  4183   \n",
       "\n",
       "         12      13   14                  15  \\\n",
       "0       905    8662   37 2011-08-09 07:16:23   \n",
       "1     19889   12908    1 2019-11-27 09:06:32   \n",
       "2      8751    6953    1 2022-08-30 08:31:11   \n",
       "3    359228  530686  492 2009-03-25 15:05:42   \n",
       "4     24515    2571    0 2020-11-10 18:32:04   \n",
       "..      ...     ...  ...                 ...   \n",
       "995    7599   16735    1 2021-08-08 21:11:55   \n",
       "996   13995   37365   49 2009-04-29 04:32:44   \n",
       "997    7568   20382    0 2020-10-29 15:54:00   \n",
       "998   41509   62310  198 2009-03-29 09:10:01   \n",
       "999   93762   38601    2 2013-05-24 14:54:41   \n",
       "\n",
       "                                                    16     17     18  \n",
       "0    https://pbs.twimg.com/profile_images/113182925...  False  False  \n",
       "1    https://pbs.twimg.com/profile_images/156963816...   True  False  \n",
       "2    https://pbs.twimg.com/profile_images/156741439...   True  False  \n",
       "3    https://pbs.twimg.com/profile_images/139801259...  False  False  \n",
       "4    https://pbs.twimg.com/profile_images/140282858...   True  False  \n",
       "..                                                 ...    ...    ...  \n",
       "995  https://pbs.twimg.com/profile_images/148562684...   True  False  \n",
       "996  https://pbs.twimg.com/profile_images/149749854...  False  False  \n",
       "997  https://pbs.twimg.com/profile_images/132548918...   True  False  \n",
       "998  https://pbs.twimg.com/profile_images/821173867...  False  False  \n",
       "999  https://pbs.twimg.com/profile_images/117486271...   True  False  \n",
       "\n",
       "[1000 rows x 19 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You code here (Please add comments in the code):\n",
    "\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "txt_qu = 'Coronavirus'\n",
    "max_tweets = 1000\n",
    "cons_key = \"2Em7SxlX9jPMfL4x97r3zMO0x\"\n",
    "cons_secret = \"sVbJzekKuiAgq83Y7gCwNVbSowqQokGVzWexKHl2cXIPceWtSd\"\n",
    "acc_tok = \"1439767876962029572-uUMt8oWRyzj9ilE5zk4uYbL93sCMPT\"\n",
    "acc_tok_sec = \"oydIGymn9bS767FVEMawE9GyGAnMmBJfaY2XXKmHnmliF\"\n",
    "auth = tweepy.OAuthHandler(cons_key, cons_secret)\n",
    "auth.set_access_token(acc_tok, acc_tok_sec)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)\n",
    "twts = tweepy.Cursor(api.search,q=text_query,lang='en').items(max_tweets)\n",
    "twts_li = [[tweet.text, tweet.created_at, tweet.id_str, tweet.user.name, tweet.user.screen_name, tweet.user.id_str, tweet.user.location, tweet.user.url, tweet.user.description, tweet.user.verified, tweet.user.followers_count, tweet.user.friends_count, tweet.user.favourites_count, tweet.user.statuses_count, tweet.user.listed_count, tweet.user.created_at, tweet.user.profile_image_url_https, tweet.user.default_profile, tweet.user.default_profile_image] for tweet in twts]\n",
    "twts_df = pd.DataFrame(twts_li)\n",
    "\n",
    "Twts = pd.DataFrame()\n",
    "Twts['User_Name'] = twts_df[4]\n",
    "Twts['Posted_Time'] = twts_df[1]\n",
    "Twts['Text'] = twts_df[0]\n",
    "Twts\n",
    "twts_df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
